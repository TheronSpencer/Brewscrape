{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREWSCRAPE\n",
    "To scrape the recipes, we will be using brewersfriend recipe search page: https://www.brewersfriend.com/search/.\n",
    "The first step is to scrape all the urls provided for each style provided in the aformentioned link. After these \n",
    "are acquired, we can scrape the contents of each individual link.\n",
    "## Explore Styles\n",
    "First let's explore the styles that are available. Since the table of links is dynamic and you can't navigate to \n",
    "specific pages I'm choosing to scrape the links by iterating though each individual style. That way, if there\n",
    "are bugs/ errors, we can start from the most recent successfully fully scraped style instead of starting on\n",
    "page 1 of all styles (5000+ pages total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of styles we will iterate through to scrape urls\n",
    "url = 'https://www.brewersfriend.com/search/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "req = Request(url, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "brewStyle_container = soup.find('select',id='styleid')\n",
    "brewStyles = []\n",
    "for i in range(0,len(brewStyle_container.find_all('option'))-1): #222\n",
    "    brewStyles.append(brewStyle_container.find_all('option')[i+1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of styles (includes multiples): 221\n",
      "['Altbier', 'Alternative Grain Beer', 'Alternative Sugar Beer', 'American Amber Ale', 'American Amber Ale', 'American Barleywine', 'American Barleywine', 'American Brown Ale', 'American Brown Ale', 'American IPA']\n",
      "\n",
      " Number of unique styles: 181\n",
      "['American Barleywine', 'Alternative Grain Beer', 'American Amber Ale', 'American Brown Ale', 'American IPA', 'Altbier', 'Alternative Sugar Beer']\n",
      "\n",
      " Number of styles with multiples: 40\n",
      "['American Amber Ale', 'American Barleywine', 'American Brown Ale', 'American IPA', 'American Pale Ale', 'American Stout', 'Baltic Porter', 'Belgian Blond Ale', 'Belgian Dark Strong Ale', 'Belgian Dubbel', 'Belgian Golden Strong Ale', 'Belgian Pale Ale', 'Belgian Tripel', 'Berliner Weisse', 'Bière de Garde', 'Blonde Ale', 'Cream Ale', 'Doppelbock', 'Eisbock', 'English Barleywine', 'English IPA', 'Flanders Red Ale', 'Foreign Extra Stout', 'Fruit Beer', 'Fruit Lambic', 'Gueuze', 'Irish Red Ale', 'Kölsch', 'Munich Dunkel', 'Munich Helles', 'Oatmeal Stout', 'Old Ale', 'Saison', 'Schwarzbier', 'Spice, Herb, or Vegetable Beer', 'Sweet Stout', 'Vienna Lager', 'Weizenbock', 'Witbier', 'Wood-Aged Beer']\n"
     ]
    }
   ],
   "source": [
    "#note there are multiples of some styles \n",
    "#this is due to an update that allowed the ingredients in newer recipes to have links to their usage/statistics\n",
    "print('Number of styles (includes multiples):',len(brewStyles))\n",
    "print(brewStyles[0:10])\n",
    "\n",
    "print('\\n','Number of unique styles:',len(set(brewStyles)))\n",
    "print(list(set(brewStyles[0:10])))\n",
    "\n",
    "multiplesList = brewStyles\n",
    "for x in list(set(brewStyles)):\n",
    "    multiplesList.remove(x)\n",
    "\n",
    "print('\\n','Number of styles with multiples:',len(multiplesList))\n",
    "print(multiplesList)\n",
    "\n",
    "#get brewStyle list again\n",
    "brewStyles = []\n",
    "for i in range(0,len(brewStyle_container.find_all('option'))-1): #222\n",
    "    brewStyles.append(brewStyle_container.find_all('option')[i+1].text)\n",
    "\n",
    "brewStyles = sorted(list(set(brewStyles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to change style names so they dont have '/' and ':' so we can save to csv\n",
    "brewStyles = [sub.replace('/-', ' shilling') for sub in brewStyles] \n",
    "brewStyles = [sub.replace('/', '=') for sub in brewStyles]\n",
    "brewStyles = [sub.replace(':', ';') for sub in brewStyles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape search table for urls for each style\n",
    "This is a dynamic webpage so we will have to use selenium.\n",
    "First we will scrape the list of 181 unique styles, then we will scrape\n",
    "the remaining 40 repeated styles afterwards since it requires slightly \n",
    "different code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicate if your running through multiples list (false for the first runthrough of the 181 unique\n",
    "#and true on the second runthrough of the 40 multiples runthrough)\n",
    "doingMultiples = True\n",
    "\n",
    "driver = webdriver.Chrome()  \n",
    "driver.get('https://www.brewersfriend.com/search/')\n",
    "\n",
    "#close popup\n",
    "xpath = \"//*[@class='fancybox-item fancybox-close']\"\n",
    "WebDriverWait(driver, 40).until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "\n",
    "#find all search bars available\n",
    "#searches[0] = method,..., searches[1,2,3,4,5,6] = [units,style,fermentables,hops,yeasts,other]\n",
    "wait = WebDriverWait(driver,45)\n",
    "xpath = \"//*[@class='search']\"\n",
    "wait.until(EC.visibility_of_all_elements_located((By.XPATH,xpath)))\n",
    "searchBars = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "# xpath = \"//*[@class='recipetitle']\"\n",
    "# recipe = driver.find_element_by_xpath(xpath)\n",
    "\n",
    "#input brew method (only interested in 'All Grain' recipes for now - approx. 105k of them total)\n",
    "searchBars[0].clear()                #clear any populated text (there isn't any in this case but its good practice)\n",
    "searchBars[0].send_keys('All Grain') #input all grain into searchbar\n",
    "searchBars[0].send_keys(Keys.ENTER)  #hit enter\n",
    "time.sleep(3)\n",
    "# wait.until(EC.staleness_of(recipe))\n",
    "\n",
    "#iterate through each brewstyle and save urls to individual csv files - we can combine them all later\n",
    "if doingMultiples == True:\n",
    "    stylesToScrape = multiplesList\n",
    "else:\n",
    "    stylesToScrape = brewStyles\n",
    "    \n",
    "for style in stylesToScrape:  \n",
    "    #input brew style\n",
    "    searchBars[2].clear()\n",
    "    time.sleep(1)\n",
    "    searchBars[2].send_keys(style)\n",
    "    time.sleep(1)\n",
    "    if doingMultiples == True:\n",
    "        searchBars[2].send_keys(Keys.DOWN)\n",
    "        time.sleep(1)\n",
    "\n",
    "    searchBars[2].send_keys(Keys.ENTER)\n",
    "    time.sleep(6)\n",
    "\n",
    "    recipeLinks = [] # initialize list to store recipeLinks\n",
    "\n",
    "    #iterate through all of the pages and get all recipe links on each page\n",
    "    #currentPage = 0 #initialize current page before entering while loop\n",
    "    #emulate do-while loop\n",
    "    while True:\n",
    "        #find all recipe links in page\n",
    "        xpath = \"//*[@class='recipetitle']\"\n",
    "        wait.until(EC.visibility_of_element_located((By.XPATH,xpath)))\n",
    "        recipes = driver.find_elements_by_xpath(xpath)\n",
    "\n",
    "        #get links for each recipe\n",
    "        for i in range(0,(len(recipes))):\n",
    "            recipeLinks.append(recipes[i].get_attribute(\"href\"))\n",
    "\n",
    "        #go to next page\n",
    "        time.sleep(random.random()*1+2)\n",
    "        #click the last available next (to avoid clicking links with recipe names that have 'next' in them)\n",
    "        #nexts = driver.find_elements_by_xpath(\"//*[contains(text(), 'Next')]\") \n",
    "        nextButton = driver.find_elements_by_xpath(\"//a[@class=' recipe_search_nav' and text()= 'Next ›']\")\n",
    "        if len(nextButton) != 0:\n",
    "            #nexts[len(nexts)-1].click() #click last available next is the correct next\n",
    "            nextButton[0].click()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        wait.until(EC.staleness_of(recipes[0]))\n",
    "\n",
    "    #need to change style name so it doesnt have '/' or ':' so we can save to csv\n",
    "    style = style.replace('/-', ' shilling').replace('/', '=').replace(':', ';')\n",
    "\n",
    "    #save to csv\n",
    "    print(\"Number of\",style, \"recipes: \", len(recipeLinks))\n",
    "    df = pd.DataFrame(recipeLinks, columns = [style])\n",
    "    if doingMultiples == True:\n",
    "        df.to_csv(style+'2.csv', encoding = 'utf-8', index = False)\n",
    "    else:\n",
    "        df.to_csv(style+'.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape brew information using urls scraped in previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBrewInfo(index):\n",
    "    beerStats_container = soup.find('div', class_ = \"description\")\n",
    "    if beerStats_container is not None:\n",
    "        tableRows = beerStats_container.find_all('span', class_='viewStats')\n",
    "        for i in range(0,len(tableRows)):\n",
    "            if tableRows[i].find('span', class_='firstLabel').text == 'Method:':\n",
    "                brewData['method'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Style:':\n",
    "                brewData['style'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Boil Time:':\n",
    "                brewData['boilTime'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Batch Size:':\n",
    "                brewData['batchSize'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Pre Boil Size:':\n",
    "                brewData['preBoilSize'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Post Boil Size:':\n",
    "                brewData['postBoilSize'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Pre Boil Gravity:':\n",
    "                if '°P' in tableRows[i].find('strong').text.strip():\n",
    "                    dP = float(tableRows[i].find('strong').text.strip().split(' °P')[0])\n",
    "                    brewData['preBoilGravity'][index] = str(round(1 + (dP/(258.6 - ((dP/258.2)*227.1))),3))\n",
    "                else:\n",
    "                    brewData['preBoilGravity'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Efficiency:':\n",
    "                brewData['efficiency'][index] = tableRows[i].find('strong').text.strip().replace('%','')\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Source:':\n",
    "                brewData['source'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Rating:':\n",
    "                brewData['rating'][index] = tableRows[i].find('span',itemprop = \"ratingValue\").text.strip()\n",
    "                brewData['numRating'][index] = tableRows[i].find('span',itemprop = \"reviewCount\").text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'No Chill:':\n",
    "                brewData['noChill'][index] = ' '.join(tableRows[i].text.split()).split('No Chill: ',1)[1]\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Hop Utilization:':\n",
    "                brewData['hopUtil'][index] = tableRows[i].find('strong').text.strip()\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Calories:':\n",
    "                brewData['calories'][index] = tableRows[i].text.strip().split()[1].replace(',','')\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'Carbs:':\n",
    "                brewData['carbs'][index] = tableRows[i].text.strip().split()[1].replace(',','')\n",
    "            elif tableRows[i].find('span', class_='firstLabel').text == 'URL:':\n",
    "                brewData['links'][index] = tableRows[i].find('a').text.strip()\n",
    "            else:\n",
    "                print(\"Theres another general stat you're not aware of: \", url)\n",
    "\n",
    "    return \n",
    "\n",
    "def getBrewInfo2(index):\n",
    "    #need to convert degrees plato to specific gravity: SG = 1+ (dP / (258.6 – ( (dP/258.2) *227.1) ) )\n",
    "    def platoToGravity(container, classValue):\n",
    "        if '°P' in container.find('div', class_ = classValue).text.strip():\n",
    "            dP = float(container.find('div', class_ = classValue).text.strip().split(' °P')[0])\n",
    "            return str(round(1 + (dP/(258.6 - ((dP/258.2)*227.1))),3))\n",
    "        else:\n",
    "            return (container.find('div', class_ = classValue).text.strip())\n",
    "\n",
    "    beerStatsOther_container = soup.find('div', class_='appbounds minstats')\n",
    "    if beerStatsOther_container is not None:\n",
    "        brewData['og'][index] = platoToGravity(beerStatsOther_container, 'value ogBatch')\n",
    "        brewData['fg'][index] = platoToGravity(beerStatsOther_container, 'value fgBatch')       \n",
    "        brewData['abv'][index] = beerStatsOther_container.find('div', class_='value abvMin').text.strip().replace('%','')\n",
    "        brewData['ibu'][index] = beerStatsOther_container.find('div', class_='value ibuMin').text.strip()\n",
    "        brewData['srm'][index] = beerStatsOther_container.find('div', class_='value srmMin').text.strip()\n",
    "        \n",
    "        if beerStatsOther_container.find('div', class_='value phMin').text.strip() != 'n/a':\n",
    "            brewData['mashPh'][index] = beerStatsOther_container.find('div', class_='value phMin').text.strip()\n",
    "      \n",
    "    return \n",
    "\n",
    "def getFermInfo(index):\n",
    "    fermAmount = []\n",
    "    fermName   = [] \n",
    "    fermPPG    = [] #points per pound per gallon\n",
    "    fermL      = [] #°L (degrees Lovibond)\n",
    "    fermBillP  = [] #bill percentage\n",
    "\n",
    "    ferm_container = soup.find('div', class_ = \"brewpart\", id = 'fermentables') #location of fermentables\n",
    "    if ferm_container is not None: \n",
    "        tableRows = ferm_container.table.find_all('tr')\n",
    "        # i = table row, j = table column \n",
    "        for i in range(1,len(tableRows)-1): #-1 to avoid last row (total weight)  \n",
    "            for j in range(0,len(tableRows[i])):\n",
    "                if j == 0: #amounts are in 1st column\n",
    "                    fermAmount.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 1: #names in 2nd column...etc\n",
    "                    #some recipes have the grain names hyperlinked, if hyperlinked there will be two\n",
    "                    #text fields: the hop name and amount of hops\n",
    "                    #e.g., this allows it to scrape just 'American - Wheat' instead of 'American - Wheat1.4 lb Wheat'\n",
    "                    if (tableRows[i].find_all('td')[j].find('a') is None):\n",
    "                        fermName.append(tableRows[i].find_all('td')[j].find('span').text.strip())\n",
    "                    else:\n",
    "                        fermName.append(tableRows[i].find_all('td')[j].find('a').text.strip())\n",
    "                elif j == 2: #ppg\n",
    "                    fermPPG.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 3: #°L (degrees Lovibond)\n",
    "                    fermL.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 4: #bill percentage\n",
    "                    fermBillP.append(tableRows[i].find_all('td')[j].text.strip().replace('%','')) \n",
    " \n",
    "    brewData['fermAmounts'][index] = fermAmount\n",
    "    brewData['fermNames'][index] = fermName\n",
    "    brewData['fermPPGs'][index] = fermPPG\n",
    "    brewData['fermLs'][index] = fermL\n",
    "    brewData['fermBillPs'][index] = fermBillP\n",
    "    \n",
    "    return \n",
    "\n",
    "def getHopInfo(index):\n",
    "    hopAmount = []\n",
    "    hopName = []\n",
    "    hopForm = [] #i.e., leaf/whole or pellet\n",
    "    hopAA = [] #alpha acid content\n",
    "    hopUse = [] #when added i.e., during boil, dry hop, etc\n",
    "    hopTime = []\n",
    "    hopIBU = [] #international bitterness units\n",
    "    hopBillP = [] #bill percentage\n",
    "\n",
    "    hop_container = soup.find('div', class_ = \"brewpart\", id = 'hops')\n",
    "    if hop_container is not None: #if hop table exists, get values\n",
    "        tableRows = hop_container.table.find_all('tr')\n",
    "        if hop_container.find('div', id='hopsSummary', style='display: none;') is not None: #if hops table isn't in summary view\n",
    "            # i = table row, j = table column\n",
    "            for i in range(1,len(tableRows)):   \n",
    "                for j in range(0,len(tableRows[i])):\n",
    "                    if j == 0: #amounts are in 1st column\n",
    "                        hopAmount.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 1: #names in 2nd column...etc\n",
    "                        #some recipes have the hop names hyperlinked, if hyperlinked there will be two\n",
    "                        #text fields: the hop name and amount of hops\n",
    "                        #e.g., this allows it to scrape just 'Citra' instead of 'Citra1 oz Citra Hops'\n",
    "                        if tableRows[i].find_all('td')[j].find('a') is None:\n",
    "                            hopName.append(tableRows[i].find_all('td')[j].find('span').text.strip())\n",
    "                        else:\n",
    "                            hopName.append(tableRows[i].find_all('td')[j].find('a').text.strip())\n",
    "                    elif j == 2: #form\n",
    "                        hopForm.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 3: #AA (degrees Lovibond)\n",
    "                        hopAA.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 4: #Use\n",
    "                        hopUse.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 5: #Time\n",
    "                        hopTime.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 6: #IBU\n",
    "                        hopIBU.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 7: #bill percentage\n",
    "                        hopBillP.append(tableRows[i].find_all('td')[j].text.strip().replace('%',''))  \n",
    "        else: #else hops is in summary view - smaller table\n",
    "            for i in range(1,len(tableRows)-1):  #-1 since last row is total (dont need)\n",
    "                for j in range(0,len(tableRows[i])): # i = table row, j = table column \n",
    "                    if j == 0: #amounts are in 1st column\n",
    "                        hopAmount.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 1: \n",
    "                        #some recipes have the hop names hyperlinked, if hyperlinked there will be two\n",
    "                        #text fields: the hop name and amount of hops\n",
    "                        #e.g., this allows it to scrape just 'Citra' instead of 'Citra1 oz Citra Hops'\n",
    "                        if tableRows[i].find_all('td')[j].find('a') is None:\n",
    "                            #names and form are in 2nd column when hops are in summary view\n",
    "                            unparsed = tableRows[i].find_all('td')[j].find('span').text.strip()\n",
    "                            name_ = unparsed.split('(')[0].strip() #name_ has underscore because name is list of recipe names\n",
    "                            form = unparsed.split('(')[1].replace(')','').strip()\n",
    "                            hopName.append(name_)\n",
    "                            hopForm.append(form)\n",
    "                        else:\n",
    "                            #names and form are in 2nd column when hops are in summary view\n",
    "                            unparsed = tableRows[i].find_all('td')[j].find('a').text.strip()\n",
    "                            name_ = unparsed.split('(')[0].strip()\n",
    "                            form = unparsed.split('(')[1].replace(')','').strip()\n",
    "                            hopName.append(name_)\n",
    "                            hopForm.append(form)\n",
    "                    elif j == 2: #IBU\n",
    "                        hopIBU.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                    elif j == 3: #bill percentage\n",
    "                        hopBillP.append(tableRows[i].find_all('td')[j].text.strip()) \n",
    "\n",
    "                    #hop AA, use, and time aren't available in summarized table\n",
    "                    hopAA.append('NA') #we can look up average AA content and add it later\n",
    "                    hopUse.append('NA')\n",
    "                    hopTime.append('NA')\n",
    "                    \n",
    "        brewData['hopAmounts'][index] = hopAmount\n",
    "        brewData['hopNames'][index] = hopName\n",
    "        brewData['hopForms'][index] = hopForm\n",
    "        brewData['hopAAs'][index] = hopAA\n",
    "        brewData['hopUses'][index] = hopUse\n",
    "        brewData['hopTimes'][index] = hopTime\n",
    "        brewData['hopIBUs'][index] = hopIBU\n",
    "        brewData['hopBillPs'][index] = hopBillP\n",
    "\n",
    "    return \n",
    "\n",
    "def getYeastInfo(index):\n",
    "    yeastName = []\n",
    "    yeastAmount = []\n",
    "    yeastAttenuation = [] #yeast attenuation (avg)\n",
    "    yeastOptTemp = [] #optimum temp\n",
    "    yeastFloc = [] #flocculation\n",
    "    yeastStarter = [] #binary yes or no\n",
    "    yeastFermTemp = [] #fermentation temp\n",
    "    yeastPitchRate = [] #pitch rate\n",
    "    \n",
    "    yeast_container = soup.find('div', class_ = \"brewpart\", id = 'yeasts')\n",
    "    if yeast_container is not None:\n",
    "        for i in range(0,len(yeast_container.find_all('tbody'))): #most recipes use 1 yeast but some have 2+\n",
    "            yeastName.append(yeast_container.find_all('thead')[i].find('span').text.strip())\n",
    "            #table is in a weird format compared to the others, also varies in dimensions\n",
    "            #so we'll take in the entire text of the table and parse it\n",
    "            unparsed = yeast_container.find_all('tbody')[i].find_all('tr')[0].find_all('td')[0].text\n",
    "            #replace any whitespace with just 1 space\n",
    "            unparsed = ' '.join(unparsed.split())\n",
    "            #make it comma delimited so we can make a list of features\n",
    "            unparsed = unparsed.replace('Attenuation', ', Attenuation').replace('Flocculation', ', Flocculation')\n",
    "            unparsed = unparsed.replace('Optimum', ', Optimum').replace('Starter', ', Starter')\n",
    "            unparsed = unparsed.replace('Fermentation', ', Fermentation').replace('Pitch', ', Pitch')\n",
    "            unparsed = unparsed.split(',')\n",
    "\n",
    "            #depending on what feature each element of the list is, assign respective value\n",
    "            for i in range(0,len(unparsed)):\n",
    "                if 'Amount:' in unparsed[i]:\n",
    "                    yeastAmount.append(unparsed[i].split('Amount:')[1].strip())\n",
    "                elif 'Attenuation (avg):' in unparsed[i]:\n",
    "                    yeastAttenuation.append(unparsed[i].split('Attenuation (avg):')[1].strip()+' (average)')\n",
    "                elif 'Attenuation (custom):' in unparsed[i]:\n",
    "                    yeastAttenuation.append(unparsed[i].split('Attenuation (custom):')[1].strip()+' (custom)')\n",
    "                elif 'Flocculation:' in unparsed[i]:\n",
    "                    yeastFloc.append(unparsed[i].split('Flocculation:')[1].strip())\n",
    "                elif 'Optimum Temp:' in unparsed[i]:\n",
    "                    yeastOptTemp.append(unparsed[i].split('Optimum Temp:')[1].strip())\n",
    "                elif 'Starter:' in unparsed[i]:\n",
    "                    yeastStarter.append(unparsed[i].split('Starter:')[1].strip())\n",
    "                elif 'Fermentation Temp:' in unparsed[i]:\n",
    "                    yeastFermTemp.append(unparsed[i].split('Fermentation Temp:')[1].strip())\n",
    "                elif 'Pitch Rate:' in unparsed[i]:\n",
    "                    yeastPitchRate.append(unparsed[i].split('Pitch Rate:')[1].strip())\n",
    "                else:\n",
    "                    print(\"Theres a yeast feature you're unaware of: \", link)\n",
    "\n",
    "        brewData['yeastNames'][index] = yeastName\n",
    "        brewData['yeastAmounts'][index] = yeastAmount\n",
    "        brewData['yeastAttenuations'][index] = yeastAttenuation\n",
    "        brewData['yeastOptTemps'][index] = yeastOptTemp\n",
    "        brewData['yeastFlocs'][index] = yeastFloc\n",
    "        brewData['yeastStarters'][index] = yeastStarter\n",
    "        brewData['yeastFermTemps'][index] = yeastFermTemp\n",
    "        brewData['yeastPitchRates'][index] = yeastPitchRate\n",
    "  \n",
    "    return \n",
    "\n",
    "def getOtherInfo(index):\n",
    "    otherAmount = []\n",
    "    otherName = []\n",
    "    otherType = []\n",
    "    otherUse = []\n",
    "    otherTime = []\n",
    "\n",
    "    other_container = soup.find('div', class_ = \"brewpart\", id = 'others')\n",
    "    if other_container is not None:\n",
    "        tableRows = other_container.table.find_all('tr')\n",
    "        # i = table row, j = table column\n",
    "        for i in range(1,len(tableRows)):  \n",
    "            for j in range(0,len(tableRows[i])):\n",
    "                if j == 0: #amounts are in 1st column\n",
    "                    otherAmount.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 1: #names in 2nd column...etc\n",
    "                    #similar problem here as with hopNames and fermNames, see them for more details\n",
    "                    if tableRows[i].find_all('td')[j].find('a') is None:\n",
    "                        otherName.append(tableRows[i].find_all('td')[j].find('span').text.strip())\n",
    "                    else:\n",
    "                        otherName.append(tableRows[i].find_all('td')[j].find('a').text.strip())\n",
    "                elif j == 2: #type\n",
    "                    otherType.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 3: #use\n",
    "                    otherUse.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 4: #time\n",
    "                    otherTime.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "    \n",
    "        brewData['otherAmounts'][index] = otherAmount\n",
    "        brewData['otherNames'][index] = otherName\n",
    "        brewData['otherTypes'][index] = otherType\n",
    "        brewData['otherUses'][index] = otherUse\n",
    "        brewData['otherTimes'][index] = otherTime\n",
    "    \n",
    "    return \n",
    "\n",
    "def getWaterInfo(index):\n",
    "    water_container = soup.find('div',class_='brewpart',id='water')\n",
    "    if water_container is not None:\n",
    "        brewData['ca'][index] = water_container.find('table').find_all('td')[0].text.strip()\n",
    "        brewData['mg'][index] = water_container.find('table').find_all('td')[1].text.strip()\n",
    "        brewData['na'][index] = water_container.find('table').find_all('td')[2].text.strip()\n",
    "        brewData['cl'][index] = water_container.find('table').find_all('td')[3].text.strip()\n",
    "        brewData['so4'][index] = water_container.find('table').find_all('td')[4].text.strip()\n",
    "        brewData['hco3'][index] = water_container.find('table').find_all('td')[5].text.strip()\n",
    "\n",
    "        #check if water notes are available, its the first water criteria that spans 6 columns\n",
    "        #the one after it is a link to mash chemistry and brewing water calculator\n",
    "        notes_container = water_container.find('table').find('td',colspan=\"6\")\n",
    "        if (notes_container is not None \n",
    "            and notes_container.text.strip()!='Mash Chemistry and Brewing Water Calculator'):\n",
    "            brewData['twNotes'][index] = notes_container.text.strip()\n",
    "            \n",
    "    return\n",
    "\n",
    "def getMashInfo(index):\n",
    "    mashAmount = []\n",
    "    mashDesc = []\n",
    "    mashType = []\n",
    "    mashTemp = []\n",
    "    mashTime = []\n",
    "    \n",
    "    mash_container = soup.find('div', class_ = \"brewpart mash_guidelines\", id = 'mashsteps')\n",
    "    if mash_container is not None:\n",
    "        #check to see if mash thickness is present, it's in the last row and spans all columns\n",
    "        if mash_container.table.find('tr', class_='bf_table_row_totals') is None: \n",
    "            k = 0\n",
    "        else:\n",
    "            k = 1\n",
    "        # i = table row, j = table column \n",
    "        tableRows = mash_container.table.find_all('tr')\n",
    "        for i in range(1,len(tableRows)-k): #-k so we dont loop over last row if mashThickness is present\n",
    "            for j in range(0,len(tableRows[i])):\n",
    "                if j == 0: #amounts are in 1st column\n",
    "                    mashAmount.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 1: #description\n",
    "                    if tableRows[i].find_all('td')[j].text.strip() == '':\n",
    "                        mashDesc.append('NA')\n",
    "                    else:\n",
    "                        mashDesc.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 2: #type\n",
    "                    if tableRows[i].find_all('td')[j].text.strip() == '':\n",
    "                        mashType.append('NA')\n",
    "                    else:\n",
    "                        mashType.append(tableRows[i].find_all('td')[j].text.strip())\n",
    "                elif j == 3: #temp\n",
    "                    mashTemp.append(tableRows[i].find_all('td')[j].text.strip().replace('--','NA'))\n",
    "                elif j == 4: #time\n",
    "                    mashTime.append(tableRows[i].find_all('td')[j].text.strip().replace('--','NA'))\n",
    "        \n",
    "        if k==1: #parse out thickness number and units\n",
    "            wordList = tableRows[len(tableRows)-1].text.strip().split()\n",
    "            thick = wordList[3]+' '+wordList[4]\n",
    "            brewData['mashThick'][index] = thick\n",
    "\n",
    "        brewData['mashAmounts'][index] = mashAmount\n",
    "        brewData['mashDescs'][index] = mashDesc\n",
    "        brewData['mashTypes'][index] = mashType\n",
    "        brewData['mashTemps'][index] = mashTemp\n",
    "        brewData['mashTimes'][index] = mashTime\n",
    "\n",
    "    return \n",
    "\n",
    "def getRemainingInfo(index): \n",
    "    brewData['recipeURL'][idx] = url\n",
    "    \n",
    "    #get name of recipe\n",
    "    name_container = soup.find('h3', itemprop='name')\n",
    "    if name_container is not None:\n",
    "        brewData['name'][index] = name_container.text.strip()\n",
    "\n",
    "    #get author of recipe\n",
    "    author_container = soup.find('span', itemprop = \"author\")\n",
    "    if author_container is not None:\n",
    "        brewData['author'][index] = author_container.text.strip()\n",
    "\n",
    "    #get date created\n",
    "    date_container = soup.find('div', class_=\"extra\") \n",
    "    if date_container is not None:\n",
    "        brewData['dateCreated'][index] = date_container.text.strip().replace('Created', '')\n",
    "    \n",
    "        #get priming info\n",
    "    priming_container = soup.find('div', class_='brewpart',  id = \"primingmethod\")\n",
    "    if priming_container is not None:\n",
    "        brewData['priming'][index] = priming_container.find('td').text.strip().replace('\\xa0','').replace('\\t','').replace('\\n',',')\n",
    "    \n",
    "    #get recipe notes \n",
    "    notes_container = soup.find('div',class_='ui message')\n",
    "    if notes_container is not None:\n",
    "        brewData['notes'][index] = notes_container.text.strip()\n",
    "\n",
    "    #get number of views recipe has and number of times other users have brewed recipe\n",
    "    viewsAndBrews_container = soup.find('div', class_='ui two statistics')\n",
    "    if viewsAndBrews_container is not None:\n",
    "        brewData['views'][index] = viewsAndBrews_container.find_all('div',class_='value')[0].text.strip()\n",
    "        brewData['brews'][index] = viewsAndBrews_container.find_all('div',class_='value')[1].text.strip()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape information from urls for each style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Amber Ale (1615) --- 5890.752970933914 seconds ---\n",
      "American Barleywine (223) --- 785.9158563613892 seconds ---\n",
      "American Brown Ale (780) --- 2820.154831647873 seconds ---\n"
     ]
    }
   ],
   "source": [
    "brewStyles = sorted(list(set(brewStyles)))\n",
    "if doingMultiples == True:\n",
    "    stylesToScrape = multiplesList\n",
    "else:\n",
    "    stylesToScrape = brewStyles\n",
    "\n",
    "for style in stylesToScrape[0:3]:\n",
    "    start_time = time.time()\n",
    "    if doingMultiples == True:\n",
    "        data = pd.read_csv(style+'2.csv', encoding = \"utf-8\")\n",
    "    else:\n",
    "        data = pd.read_csv(style+'.csv', encoding = \"utf-8\")\n",
    "\n",
    "    brewFeatures = ['recipeURL','name','author','method','style','boilTime','batchSize','preBoilSize',\n",
    "                    'postBoilSize','preBoilGravity','efficiency','source','noChill','rating','numRating',\n",
    "                    'hopUtil','calories','carbs','views','brews','links','dateCreated','og','fg','abv',\n",
    "                    'ibu','srm','mashPh','fermNames','fermAmounts','fermPPGs','fermLs','fermBillPs',\n",
    "                    'hopAmounts','hopNames','hopForms','hopAAs','hopUses','hopTimes','hopIBUs','hopBillPs',\n",
    "                    'yeastNames','yeastAmounts','yeastAttenuations','yeastOptTemps','yeastFlocs',\n",
    "                    'yeastStarters','yeastFermTemps','yeastPitchRates','ca','mg','na','cl','so4','hco3',\n",
    "                    'twNotes','priming', 'otherNames','otherAmounts','otherTypes','otherUses','otherTimes',\n",
    "                    'mashAmounts','mashDescs','mashTypes','mashTemps','mashTimes','mashThick','notes']\n",
    "\n",
    "    #initialize dictionary of features\n",
    "    brewData = {feature: [] for feature in brewFeatures}\n",
    "\n",
    "    #loop through each recipe\n",
    "    idx = -1\n",
    "    for link in data[style]:\n",
    "\n",
    "        url = link\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "        req = Request(url, headers=hdr)\n",
    "\n",
    "        try: #try to open url\n",
    "            page = urlopen(req)\n",
    "        except HTTPError as e:\n",
    "            print('The server couldn\\'t fulfill the request.')\n",
    "            print('Error code: ', e.code)\n",
    "            print(link)\n",
    "            sys.exit(1)\n",
    "        except URLError as e:\n",
    "            print('We failed to reach a server.')\n",
    "            print('Reason: ', e.reason)\n",
    "            print(link)\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            idx = idx+1   \n",
    "            soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "            #initialize all features as 'NA'\n",
    "            for feature in brewData:\n",
    "                brewData[feature].append('NA')\n",
    "\n",
    "            #get all info, change 'NA's to correct values only if theyre present\n",
    "            getBrewInfo(idx)\n",
    "            getBrewInfo2(idx)\n",
    "            getFermInfo(idx)\n",
    "            getMashInfo(idx)\n",
    "            getWaterInfo(idx)\n",
    "            getOtherInfo(idx)\n",
    "            getYeastInfo(idx)\n",
    "            getHopInfo(idx)\n",
    "            getRemainingInfo(idx)\n",
    "            \n",
    "            # pause loop to avoid overloading server/ getting banned\n",
    "            time.sleep(random.randint(1,2)+1)\n",
    "\n",
    "    df = pd.DataFrame(brewData)      \n",
    "\n",
    "    if doingMultiples == True:\n",
    "        df.to_csv(style+'2.csv', encoding = 'utf-8', index = False)\n",
    "    else:\n",
    "        df.to_csv(style+'.csv', encoding = 'utf-8', index = False)\n",
    "        \n",
    "    print(style,'('+str(len(data[style]))+')',\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all style csv's into one file\n",
    "We will now merge all individual style csv files into one master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of styles (includes multiples): 221\n",
      "['Altbier', 'Alternative Grain Beer', 'Alternative Sugar Beer', 'American Amber Ale', 'American Amber Ale', 'American Barleywine', 'American Barleywine', 'American Brown Ale', 'American Brown Ale', 'American IPA', 'American IPA', 'American Lager', 'American Light Lager', 'American Pale Ale', 'American Pale Ale', 'American Porter', 'American Stout', 'American Stout', 'American Strong Ale', 'American Wheat Beer']\n",
      "\n",
      " Number of styles with multiples: 40\n",
      "['American Amber Ale', 'American Barleywine', 'American Brown Ale', 'American IPA', 'American Pale Ale', 'American Stout', 'Baltic Porter', 'Belgian Blond Ale', 'Belgian Dark Strong Ale', 'Belgian Dubbel', 'Belgian Golden Strong Ale', 'Belgian Pale Ale', 'Belgian Tripel', 'Berliner Weisse', 'Bière de Garde', 'Blonde Ale', 'Cream Ale', 'Doppelbock', 'Eisbock', 'English Barleywine', 'English IPA', 'Flanders Red Ale', 'Foreign Extra Stout', 'Fruit Beer', 'Fruit Lambic', 'Gueuze', 'Irish Red Ale', 'Kölsch', 'Munich Dunkel', 'Munich Helles', 'Oatmeal Stout', 'Old Ale', 'Saison', 'Schwarzbier', 'Spice, Herb, or Vegetable Beer', 'Sweet Stout', 'Vienna Lager', 'Weizenbock', 'Witbier', 'Wood-Aged Beer']\n",
      "\n",
      " Number of unique styles: 181\n",
      "['Altbier', 'Alternative Grain Beer', 'Alternative Sugar Beer', 'American Amber Ale', 'American Barleywine', 'American Brown Ale', 'American IPA', 'American Lager', 'American Light Lager', 'American Pale Ale', 'American Porter', 'American Stout', 'American Strong Ale', 'American Wheat Beer', 'American Wheat or Rye Beer', 'Apple Wine', 'Australian Sparkling Ale', 'Autumn Seasonal Beer', 'Baltic Porter', 'Belgian Blond Ale']\n"
     ]
    }
   ],
   "source": [
    "###  Identify Styles and Style Multiples\n",
    "brewStyles = list(pd.read_csv('stylesList.csv',encoding='utf-8')['Styles'])\n",
    "print('Number of styles (includes multiples):',len(brewStyles))\n",
    "print(list(brewStyles[0:20]))\n",
    "\n",
    "multiplesList = brewStyles.copy()\n",
    "for x in list(set(brewStyles)):\n",
    "    multiplesList.remove(x)\n",
    "\n",
    "print('\\n','Number of styles with multiples:',len(multiplesList))\n",
    "print(multiplesList)\n",
    "\n",
    "uniqueStyles = sorted(list(set(brewStyles)))\n",
    "print('\\n','Number of unique styles:',len(uniqueStyles))\n",
    "print(uniqueStyles[0:20])\n",
    "\n",
    "#need to change style names so they dont have '/' and ':' so we can save to csv\n",
    "brewStyles = [sub.replace('/-', ' shilling') for sub in brewStyles] \n",
    "brewStyles = [sub.replace('/', '=') for sub in brewStyles]\n",
    "brewStyles = [sub.replace(':', ';') for sub in brewStyles]\n",
    "\n",
    "#need to change style names so they dont have '/' and ':' so we can save to csv\n",
    "uniqueStyles = [sub.replace('/-', ' shilling') for sub in uniqueStyles] \n",
    "uniqueStyles = [sub.replace('/', '=') for sub in uniqueStyles]\n",
    "uniqueStyles = [sub.replace(':', ';') for sub in uniqueStyles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Common Perry', 'New Zealand Pilsner', 'Traditional Perry']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify styles there arent any csv's for (i.e., the styles there were no all-grain recipes for)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "path = r'C:\\Users\\Theron\\Documents\\Brewscrape\\Styles'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            files.append(file.replace('.csv',''))\n",
    "    \n",
    "list(set(uniqueStyles)-set(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove styles that had no all grain recipes: common perry, new zealand pilsner\n",
    "uniqueStyles.remove('Common Perry')\n",
    "uniqueStyles.remove('Traditional Perry')\n",
    "uniqueStyles.remove('New Zealand Pilsner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theron\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Theron\\Documents\\Brewscrape\\Styles'           # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "#remove styles list\n",
    "all_files.remove('C:\\\\Users\\\\Theron\\\\Documents\\\\Brewscrape\\\\Styles\\\\stylesList.csv')\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "data = pd.concat(df_from_each_file, ignore_index=True)\n",
    "#drop rows that have all na's, in this case if method is na, the rest are as well except for recipeURL\n",
    "data = data.dropna(axis=0,how='all',subset=['method'])\n",
    "#drop recipes that use method other than all grain (BIAB, extract, etc)\n",
    "data = data[data.method == 'All Grain']\n",
    "\n",
    "#do some cleaning before saving\n",
    "data['views'] = [float(str(x).replace(',','')) for x in data.views]\n",
    "data['boilTime'] = [float(x.split(' min')[0]) for x in data.boilTime]\n",
    "\n",
    "#convert liters to gallons\n",
    "#there are 0.265172 gallons per liter\n",
    "data['batchSize'] = list(map(lambda x: round(float(x.split(' ')[0])*0.264172,2) if x.split(' ')[1]=='liters' \n",
    "                                                else float(x.split(' ')[0]), data.batchSize))\n",
    "data['preBoilSize'] = list(map(lambda x: round(float(x.split(' ')[0])*0.264172,2) if x.split(' ')[1]=='liters' \n",
    "                                                else float(x.split(' ')[0]), data.preBoilSize))\n",
    "data['postBoilSize'] = list(map(lambda x: round(float(x.split(' ')[0])*0.264172,2) \n",
    "                                if (type(x)!=float and x.split(' ')[1]=='liters')\n",
    "                                else (float(x.split(' ')[0] if (type(x)!=float and x.split(' ')[1]=='gallons')\n",
    "                                            else float(x))), data.postBoilSize))\n",
    "data.to_csv('allStylesData.csv',encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape ingredient information provided on brewersfriend\n",
    "This information will be used to clean the ingredients to be used in the beer classifier and recipe generator. <br>\n",
    "https://www.brewersfriend.com/hops/ <br> https://www.brewersfriend.com/fermentables/ <br> https://www.brewersfriend.com/yeasts/ <br> https://www.brewersfriend.com/other/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape hop information\n",
    "(will eventually make a function that will scrape all 4 ingredient types using same code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n",
      "        hop        type avg_AA   use recipe_nums\n",
      "0   Admiral      Pellet   14.4  Boil       3,755\n",
      "1   Ahtanum      Pellet    5.4  Boil      15,746\n",
      "2  Amarillo      Pellet    8.6  Boil     195,778\n",
      "3    Apollo        Plug   18.9  Boil      12,469\n",
      "4    Aquila  Leaf/Whole    6.7  Boil          75\n"
     ]
    }
   ],
   "source": [
    "#get list of styles we will iterate through to scrape urls\n",
    "url = 'https://www.brewersfriend.com/hops/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "req = Request(url, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "hop_table =  soup.find('table', class_='browse-results').find('tbody')\n",
    "hop_rows = hop_table.find_all('tr')\n",
    "\n",
    "hop_features = ['hop','type','avg_AA','use','recipe_nums']\n",
    "hop_data = {feature: [] for feature in hop_features}\n",
    "\n",
    "for i in range(0,len(hop_rows)):\n",
    "    hop_data['hop'].append(hop_rows[i].find_all('td')[0].text) #name is in 1st column\n",
    "    hop_data['type'].append(hop_rows[i].find_all('td')[1].text)\n",
    "    hop_data['avg_AA'].append(hop_rows[i].find_all('td')[2].text)\n",
    "    hop_data['use'].append(hop_rows[i].find_all('td')[3].text)\n",
    "    hop_data['recipe_nums'].append(hop_rows[i].find_all('td')[4].text) #num of recipes is in 5th column\n",
    "\n",
    "\n",
    "hop_df = pd.DataFrame(hop_data)\n",
    "print(len(hop_df))\n",
    "print(hop_df[0:5])\n",
    "hop_df.to_csv('hop_info.csv',encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape fermentable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "       fermentable  country category             type   color  ppg recipe_nums\n",
      "0       Abbey Malt   German    Grain        Base malt  17 °L    33       3,089\n",
      "1          Acerola             Fruit            Fruit   0 °L   1.5           5\n",
      "2  Acidulated Malt   German    Grain  Acidulated malt   3 °L    27      50,606\n",
      "3     Agave Nectar             Sugar            Sugar   2 °L    35         305\n",
      "4         Ale Malt  Ireland    Grain        Base malt   3 °L    37       1,081\n"
     ]
    }
   ],
   "source": [
    "#get list of styles we will iterate through to scrape urls\n",
    "url = 'https://www.brewersfriend.com/fermentables/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "req = Request(url, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "ferm_table =  soup.find('table', class_='browse-results').find('tbody')\n",
    "ferm_rows = ferm_table.find_all('tr')\n",
    "\n",
    "ferm_features = ['fermentable','country','category','type',\n",
    "                 'color','ppg','recipe_nums']\n",
    "ferm_data = {feature: [] for feature in ferm_features}\n",
    "\n",
    "for i in range(0,len(ferm_rows)):\n",
    "    ferm_data['fermentable'].append(ferm_rows[i].find_all('td')[0].text) #name is in 1st column\n",
    "    ferm_data['country'].append(ferm_rows[i].find_all('td')[1].text) \n",
    "    ferm_data['category'].append(ferm_rows[i].find_all('td')[2].text)\n",
    "    ferm_data['type'].append(ferm_rows[i].find_all('td')[3].text) \n",
    "    ferm_data['color'].append(ferm_rows[i].find_all('td')[4].text) \n",
    "    ferm_data['ppg'].append(ferm_rows[i].find_all('td')[5].text)\n",
    "    ferm_data['recipe_nums'].append(ferm_rows[i].find_all('td')[6].text) #num of recipes is in 7th column\n",
    "\n",
    "ferm_df = pd.DataFrame(ferm_data)\n",
    "print(len(ferm_df))\n",
    "print(ferm_df[0:5])\n",
    "ferm_df.to_csv('ferm_info.csv',encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape yeast information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "                           yeast lab   code  type alcohol_tolerance  \\\n",
      "0     - Saccharomycodes ludwigii             Ales              High   \n",
      "1                    Coopers Ale   -          Ale            Medium   \n",
      "2                      Doric Ale   -          Ale            Medium   \n",
      "3                       Edme Ale   -          Ale            Medium   \n",
      "4  Gervin Ale (by Muntons) GV-12   -  GV-12   Ale               n/a   \n",
      "\n",
      "  flocculation attenuation min_temp max_temp  \n",
      "0          Low          0%      0°F      0°F  \n",
      "1         High         72%     68°F     80°F  \n",
      "2       Medium         74%     62°F     72°F  \n",
      "3       Medium         74%     62°F     70°F  \n",
      "4         High         77%     57°F     70°F  \n"
     ]
    }
   ],
   "source": [
    "#get list of styles we will iterate through to scrape urls\n",
    "url = 'https://www.brewersfriend.com/yeasts/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "req = Request(url, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "yeast_table =  soup.find('table', class_='browse-results').find('tbody')\n",
    "yeast_rows = yeast_table.find_all('tr')\n",
    "\n",
    "yeast_features = ['yeast','lab','code','type','alcohol_tolerance','flocculation',\n",
    "                  'attenuation','min_temp','max_temp']\n",
    "yeast_data = {feature: [] for feature in yeast_features}\n",
    "\n",
    "for i in range(0,len(yeast_rows)):\n",
    "    yeast_data['yeast'].append(yeast_rows[i].find_all('td')[0].text) #name is in 1st column\n",
    "    yeast_data['lab'].append(yeast_rows[i].find_all('td')[1].text) \n",
    "    yeast_data['code'].append(yeast_rows[i].find_all('td')[2].text)\n",
    "    yeast_data['type'].append(yeast_rows[i].find_all('td')[3].text) \n",
    "    yeast_data['alcohol_tolerance'].append(yeast_rows[i].find_all('td')[4].text) \n",
    "    yeast_data['flocculation'].append(yeast_rows[i].find_all('td')[5].text)\n",
    "    yeast_data['attenuation'].append(yeast_rows[i].find_all('td')[6].text) \n",
    "    yeast_data['min_temp'].append(yeast_rows[i].find_all('td')[7].text)\n",
    "    yeast_data['max_temp'].append(yeast_rows[i].find_all('td')[8].text) #max temp is in 9th column\n",
    "    \n",
    "yeast_df = pd.DataFrame(yeast_data)\n",
    "print(len(yeast_df))\n",
    "print(yeast_df[0:5])\n",
    "yeast_df.to_csv('yeast_info.csv',encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape other ingredient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593\n",
      "                    ingredient       type   use num_recipes\n",
      "0                     Cinnamon      Spice  Boil          37\n",
      "1    Servomyces Yeast Nutrient      Other  Boil          28\n",
      "2                10% Phos Acid  Water Agt  Mash          52\n",
      "3  10% Phos Acid To Sparge 5.4  Water Agt  Mash          31\n",
      "4          10% Phosphoric Acid  Water Agt  Mash          91\n"
     ]
    }
   ],
   "source": [
    "#get list of styles we will iterate through to scrape urls\n",
    "url = 'https://www.brewersfriend.com/other/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'} # used to avoid 403 error\n",
    "req = Request(url, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "other_table =  soup.find('table', class_='browse-results').find('tbody')\n",
    "other_rows = other_table.find_all('tr')\n",
    "\n",
    "other_features = ['ingredient','type','use','num_recipes']\n",
    "other_data = {feature: [] for feature in other_features}\n",
    "\n",
    "for i in range(0,len(other_rows)):\n",
    "    other_data['ingredient'].append(other_rows[i].find_all('td')[0].text) #name is in 1st column\n",
    "    other_data['type'].append(other_rows[i].find_all('td')[1].text) \n",
    "    other_data['use'].append(other_rows[i].find_all('td')[2].text)\n",
    "    other_data['num_recipes'].append(other_rows[i].find_all('td')[3].text) \n",
    "    \n",
    "other_df = pd.DataFrame(other_data)\n",
    "print(len(other_df))\n",
    "print(other_df[0:5])\n",
    "other_df.to_csv('other_info.csv',encoding = 'utf-8',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
